import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error

# Data
X, y = make_regression(n_samples=1000, n_features=10, noise=0.1, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the scalers
X_scaler = StandardScaler()
y_scaler = StandardScaler()

# Fit the scalers on the training data and transform
X_train_scaled = X_scaler.fit_transform(X_train)
y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1, 1))

# Transform the test data using the fitted scalers
X_test_scaled = X_scaler.transform(X_test)
y_test_scaled = y_scaler.transform(y_test.reshape(-1, 1))


X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)
X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32)
y_test_tensor = torch.tensor(y_test_scaled, dtype=torch.float32)
train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=64, shuffle=True)
test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=64)

# Model
class Net(nn.Module):
    def __init__(self, in_size, h):
        super().__init__()
        self.fc1 = nn.Linear(in_size, h)
        self.act = nn.ReLU()
        self.fc2 = nn.Linear(h, 1)
    def forward(self, x): return self.fc2(self.act(self.fc1(x)))

input_size = X_train_tensor.shape[1]
hidden_size = 10  # A fixed hidden layer size
model = Net(input_size, hidden_size)

# Optimizer and Loss
learning_rate = 0.01  # A fixed learning rate
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
criterion = nn.MSELoss()

# Train
epochs = 10
for epoch in range(epochs):
    for inputs, targets in train_loader:
        optimizer.zero_grad(); outputs = model(inputs); loss = criterion(outputs, targets); loss.backward(); optimizer.step()
    print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')

# Evaluate
model.eval()
with torch.no_grad():
    y_pred = y_scaler.inverse_transform(model(X_test_tensor).numpy())
    y_true = y_scaler.inverse_transform(y_test_tensor.numpy())
    final_mse = mean_squared_error(y_true, y_pred)
    print(f'Final Test MSE: {final_mse:.4f}')
